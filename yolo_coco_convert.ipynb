{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3378153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "import sys\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from tensorboard.backend.event_processing import event_accumulator as ea\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140e0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category file, one category per line\n",
    "yolo_format_classes_path = 'dataset/classes.txt' #absolute path to the file where the categories are stored. The file should contain one category per line.\n",
    "# Write the category according to your own data set. \n",
    "\n",
    "#Read the categories file and extract all categories\n",
    "with open(yolo_format_classes_path,'r') as f1:\n",
    "    lines1 = f1.readlines()\n",
    "categories = []\n",
    "for j,label in enumerate(lines1):\n",
    "    label = label.strip()\n",
    "    categories.append({'id':j+1,'name':label,'supercategory': label})\n",
    "    \n",
    "write_json_context = dict()\n",
    "write_json_context['info'] = {'description': '', 'url': '', 'version': '', 'year': 2021, 'contributor': '', 'date_created': '2021-02-12 11:00:08.5'}\n",
    "write_json_context['licenses'] = [{'id': 1, 'name': None, 'url': None}]\n",
    "write_json_context['categories'] = categories\n",
    "write_json_context['images'] = []\n",
    "write_json_context['annotations'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f494c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO formatted JSON saved to dataset/images/train/train.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Initialize the context for the COCO format\n",
    "write_json_context = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [\n",
    "        {\"id\": 1, \"name\": \"WBC\", \"supercategory\": \"WBC\"},\n",
    "        {\"id\": 2, \"name\": \"RBC\", \"supercategory\": \"RBC\"},\n",
    "        {\"id\": 3, \"name\": \"Platelet\", \"supercategory\": \"Platelet\"}\n",
    "    ],\n",
    "    \"info\": {\n",
    "        \"description\": \"Dataset for classification\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2021,\n",
    "        \"contributor\": \"\",\n",
    "        \"date_created\": \"2021-02-12 11:00:08.5\"\n",
    "    },\n",
    "    \"licenses\": [{\"id\": 1, \"name\": \"Unknown\", \"url\": \"\"}]\n",
    "}\n",
    "\n",
    "# Initialize the image and annotation counters\n",
    "file_number = 1\n",
    "num_bboxes = 1  # Global annotation ID counter, maintained across all runs\n",
    "\n",
    "# Directories for images and annotations\n",
    "directory_labels = os.fsencode(\"dataset/labels/train\")\n",
    "directory_images = os.fsencode(\"dataset/images/train\")\n",
    "\n",
    "# Loop through images in the 'train' folder\n",
    "for file in os.listdir(directory_images):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(directory_images.decode(\"utf-8\"), filename)\n",
    "        base = os.path.basename(img_path)\n",
    "        file_name_without_ext = os.path.splitext(base)[0]  # name of the file without extension\n",
    "        yolo_annotation_path = os.path.join(directory_labels.decode(\"utf-8\"), file_name_without_ext + \".\" + 'txt')\n",
    "\n",
    "        # Image context info\n",
    "        img_name = os.path.basename(img_path)\n",
    "        img_context = {}\n",
    "        height, width = cv2.imread(img_path).shape[:2]\n",
    "        img_context['file_name'] = img_name\n",
    "        img_context['height'] = height\n",
    "        img_context['width'] = width\n",
    "        img_context['date_captured'] = '2021-02-12 11:00:08.5'\n",
    "        img_context['id'] = file_number  # image id\n",
    "        img_context['license'] = 1\n",
    "        img_context['coco_url'] = ''\n",
    "        img_context['flickr_url'] = ''\n",
    "        write_json_context['images'].append(img_context)\n",
    "\n",
    "        # Read YOLO annotations and convert to COCO format\n",
    "        with open(yolo_annotation_path, 'r') as f2:\n",
    "            lines2 = f2.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines2):  # Loop through each annotation in the image\n",
    "            line = line.split(' ')\n",
    "            bbox_dict = {}\n",
    "            class_id, x_yolo, y_yolo, width_yolo, height_yolo = line[0:]\n",
    "            x_yolo, y_yolo, width_yolo, height_yolo, class_id = float(x_yolo), float(y_yolo), float(width_yolo), float(height_yolo), int(class_id)\n",
    "            bbox_dict['id'] = num_bboxes  # Assign unique annotation ID across all files\n",
    "            bbox_dict['image_id'] = file_number\n",
    "            bbox_dict['category_id'] = class_id + 1  # COCO categories start at 1, YOLO starts at 0\n",
    "            bbox_dict['iscrowd'] = 0  # Not marked as crowd\n",
    "\n",
    "            # Calculate the absolute dimensions of the bounding box\n",
    "            h, w = abs(height_yolo * height), abs(width_yolo * width)\n",
    "            bbox_dict['area'] = h * w\n",
    "            x_coco = round(x_yolo * width - (w / 2))\n",
    "            y_coco = round(y_yolo * height - (h / 2))\n",
    "\n",
    "            # Ensure bounding box coordinates are within the image\n",
    "            if x_coco < 0:\n",
    "                x_coco = 1\n",
    "            if y_coco < 0:\n",
    "                y_coco = 1\n",
    "\n",
    "            bbox_dict['bbox'] = [x_coco, y_coco, w, h]\n",
    "            bbox_dict['segmentation'] = [[x_coco, y_coco, x_coco + w, y_coco, x_coco + w, y_coco + h, x_coco, y_coco + h]]\n",
    "\n",
    "            write_json_context['annotations'].append(bbox_dict)\n",
    "            num_bboxes += 1  # Increment the annotation ID\n",
    "\n",
    "        file_number += 1  # Increment image ID\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Finally, save the result to a JSON file\n",
    "coco_format_save_path = 'dataset/images/train/train.json'\n",
    "with open(coco_format_save_path, 'w') as fw:\n",
    "    json.dump(write_json_context, fw)\n",
    "\n",
    "print(f\"COCO formatted JSON saved to {coco_format_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b551b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO formatted JSON saved to dataset/images/test/test.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Initialize the context for the COCO format\n",
    "write_json_context = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [\n",
    "        {\"id\": 1, \"name\": \"WBC\", \"supercategory\": \"WBC\"},\n",
    "        {\"id\": 2, \"name\": \"RBC\", \"supercategory\": \"RBC\"},\n",
    "        {\"id\": 3, \"name\": \"Platelet\", \"supercategory\": \"Platelet\"}\n",
    "    ],\n",
    "    \"info\": {\n",
    "        \"description\": \"Dataset for classification\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2021,\n",
    "        \"contributor\": \"\",\n",
    "        \"date_created\": \"2021-02-12 11:00:08.5\"\n",
    "    },\n",
    "    \"licenses\": [{\"id\": 1, \"name\": \"Unknown\", \"url\": \"\"}]\n",
    "}\n",
    "\n",
    "# Initialize the image and annotation counters\n",
    "file_number = 1\n",
    "num_bboxes = 1  # Global annotation ID counter, maintained across all runs\n",
    "\n",
    "# Directories for images and annotations\n",
    "directory_labels = os.fsencode(\"dataset/labels/test\")\n",
    "directory_images = os.fsencode(\"dataset/images/test\")\n",
    "\n",
    "# Loop through images in the 'train' folder\n",
    "for file in os.listdir(directory_images):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(directory_images.decode(\"utf-8\"), filename)\n",
    "        base = os.path.basename(img_path)\n",
    "        file_name_without_ext = os.path.splitext(base)[0]  # name of the file without extension\n",
    "        yolo_annotation_path = os.path.join(directory_labels.decode(\"utf-8\"), file_name_without_ext + \".\" + 'txt')\n",
    "\n",
    "        # Image context info\n",
    "        img_name = os.path.basename(img_path)\n",
    "        img_context = {}\n",
    "        height, width = cv2.imread(img_path).shape[:2]\n",
    "        img_context['file_name'] = img_name\n",
    "        img_context['height'] = height\n",
    "        img_context['width'] = width\n",
    "        img_context['date_captured'] = '2021-02-12 11:00:08.5'\n",
    "        img_context['id'] = file_number  # image id\n",
    "        img_context['license'] = 1\n",
    "        img_context['coco_url'] = ''\n",
    "        img_context['flickr_url'] = ''\n",
    "        write_json_context['images'].append(img_context)\n",
    "\n",
    "        # Read YOLO annotations and convert to COCO format\n",
    "        with open(yolo_annotation_path, 'r') as f2:\n",
    "            lines2 = f2.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines2):  # Loop through each annotation in the image\n",
    "            line = line.split(' ')\n",
    "            bbox_dict = {}\n",
    "            class_id, x_yolo, y_yolo, width_yolo, height_yolo = line[0:]\n",
    "            x_yolo, y_yolo, width_yolo, height_yolo, class_id = float(x_yolo), float(y_yolo), float(width_yolo), float(height_yolo), int(class_id)\n",
    "            bbox_dict['id'] = num_bboxes  # Assign unique annotation ID across all files\n",
    "            bbox_dict['image_id'] = file_number\n",
    "            bbox_dict['category_id'] = class_id + 1  # COCO categories start at 1, YOLO starts at 0\n",
    "            bbox_dict['iscrowd'] = 0  # Not marked as crowd\n",
    "\n",
    "            # Calculate the absolute dimensions of the bounding box\n",
    "            h, w = abs(height_yolo * height), abs(width_yolo * width)\n",
    "            bbox_dict['area'] = h * w\n",
    "            x_coco = round(x_yolo * width - (w / 2))\n",
    "            y_coco = round(y_yolo * height - (h / 2))\n",
    "\n",
    "            # Ensure bounding box coordinates are within the image\n",
    "            if x_coco < 0:\n",
    "                x_coco = 1\n",
    "            if y_coco < 0:\n",
    "                y_coco = 1\n",
    "\n",
    "            bbox_dict['bbox'] = [x_coco, y_coco, w, h]\n",
    "            bbox_dict['segmentation'] = [[x_coco, y_coco, x_coco + w, y_coco, x_coco + w, y_coco + h, x_coco, y_coco + h]]\n",
    "\n",
    "            write_json_context['annotations'].append(bbox_dict)\n",
    "            num_bboxes += 1  # Increment the annotation ID\n",
    "\n",
    "        file_number += 1  # Increment image ID\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Finally, save the result to a JSON file\n",
    "coco_format_save_path = 'dataset/images/test/test.json'\n",
    "with open(coco_format_save_path, 'w') as fw:\n",
    "    json.dump(write_json_context, fw)\n",
    "\n",
    "print(f\"COCO formatted JSON saved to {coco_format_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe47a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO formatted JSON saved to dataset/images/val/val.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Initialize the context for the COCO format\n",
    "write_json_context = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [\n",
    "        {\"id\": 1, \"name\": \"WBC\", \"supercategory\": \"WBC\"},\n",
    "        {\"id\": 2, \"name\": \"RBC\", \"supercategory\": \"RBC\"},\n",
    "        {\"id\": 3, \"name\": \"Platelet\", \"supercategory\": \"Platelet\"}\n",
    "    ],\n",
    "    \"info\": {\n",
    "        \"description\": \"Dataset for classification\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2021,\n",
    "        \"contributor\": \"\",\n",
    "        \"date_created\": \"2021-02-12 11:00:08.5\"\n",
    "    },\n",
    "    \"licenses\": [{\"id\": 1, \"name\": \"Unknown\", \"url\": \"\"}]\n",
    "}\n",
    "\n",
    "# Initialize the image and annotation counters\n",
    "file_number = 1\n",
    "num_bboxes = 1  # Global annotation ID counter, maintained across all runs\n",
    "\n",
    "# Directories for images and annotations\n",
    "directory_labels = os.fsencode(\"dataset/labels/val\")\n",
    "directory_images = os.fsencode(\"dataset/images/val\")\n",
    "\n",
    "# Loop through images in the 'train' folder\n",
    "for file in os.listdir(directory_images):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(directory_images.decode(\"utf-8\"), filename)\n",
    "        base = os.path.basename(img_path)\n",
    "        file_name_without_ext = os.path.splitext(base)[0]  # name of the file without extension\n",
    "        yolo_annotation_path = os.path.join(directory_labels.decode(\"utf-8\"), file_name_without_ext + \".\" + 'txt')\n",
    "\n",
    "        # Image context info\n",
    "        img_name = os.path.basename(img_path)\n",
    "        img_context = {}\n",
    "        height, width = cv2.imread(img_path).shape[:2]\n",
    "        img_context['file_name'] = img_name\n",
    "        img_context['height'] = height\n",
    "        img_context['width'] = width\n",
    "        img_context['date_captured'] = '2021-02-12 11:00:08.5'\n",
    "        img_context['id'] = file_number  # image id\n",
    "        img_context['license'] = 1\n",
    "        img_context['coco_url'] = ''\n",
    "        img_context['flickr_url'] = ''\n",
    "        write_json_context['images'].append(img_context)\n",
    "\n",
    "        # Read YOLO annotations and convert to COCO format\n",
    "        with open(yolo_annotation_path, 'r') as f2:\n",
    "            lines2 = f2.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines2):  # Loop through each annotation in the image\n",
    "            line = line.split(' ')\n",
    "            bbox_dict = {}\n",
    "            class_id, x_yolo, y_yolo, width_yolo, height_yolo = line[0:]\n",
    "            x_yolo, y_yolo, width_yolo, height_yolo, class_id = float(x_yolo), float(y_yolo), float(width_yolo), float(height_yolo), int(class_id)\n",
    "            bbox_dict['id'] = num_bboxes  # Assign unique annotation ID across all files\n",
    "            bbox_dict['image_id'] = file_number\n",
    "            bbox_dict['category_id'] = class_id + 1  # COCO categories start at 1, YOLO starts at 0\n",
    "            bbox_dict['iscrowd'] = 0  # Not marked as crowd\n",
    "\n",
    "            # Calculate the absolute dimensions of the bounding box\n",
    "            h, w = abs(height_yolo * height), abs(width_yolo * width)\n",
    "            bbox_dict['area'] = h * w\n",
    "            x_coco = round(x_yolo * width - (w / 2))\n",
    "            y_coco = round(y_yolo * height - (h / 2))\n",
    "\n",
    "            # Ensure bounding box coordinates are within the image\n",
    "            if x_coco < 0:\n",
    "                x_coco = 1\n",
    "            if y_coco < 0:\n",
    "                y_coco = 1\n",
    "\n",
    "            bbox_dict['bbox'] = [x_coco, y_coco, w, h]\n",
    "            bbox_dict['segmentation'] = [[x_coco, y_coco, x_coco + w, y_coco, x_coco + w, y_coco + h, x_coco, y_coco + h]]\n",
    "\n",
    "            write_json_context['annotations'].append(bbox_dict)\n",
    "            num_bboxes += 1  # Increment the annotation ID\n",
    "\n",
    "        file_number += 1  # Increment image ID\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Finally, save the result to a JSON file\n",
    "coco_format_save_path = 'dataset/images/val/val.json'\n",
    "with open(coco_format_save_path, 'w') as fw:\n",
    "    json.dump(write_json_context, fw)\n",
    "\n",
    "print(f\"COCO formatted JSON saved to {coco_format_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdf0935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] No duplicate annotation IDs found.\n",
      "[VAL] No duplicate annotation IDs found.\n",
      "[TEST] No duplicate annotation IDs found.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Paths to your COCO annotation JSON files\n",
    "json_paths = {\n",
    "    \"train\": \"dataset/images/train/train.json\",\n",
    "    \"val\": \"dataset/images/val/val.json\",\n",
    "    \"test\": \"dataset/images/test/test.json\"\n",
    "}\n",
    "\n",
    "def check_duplicate_annotation_ids(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    annotation_ids = [ann['id'] for ann in data.get('annotations', [])]\n",
    "    duplicates = [item for item, count in Counter(annotation_ids).items() if count > 1]\n",
    "    return duplicates\n",
    "\n",
    "# Run check\n",
    "for split, path in json_paths.items():\n",
    "    duplicates = check_duplicate_annotation_ids(path)\n",
    "    if duplicates:\n",
    "        print(f\"[{split.upper()}] Duplicate annotation IDs found: {duplicates[:10]}{'...' if len(duplicates) > 10 else ''}\")\n",
    "    else:\n",
    "        print(f\"[{split.upper()}] No duplicate annotation IDs found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
